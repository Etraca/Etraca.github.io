---
layout:     post
title:      kafka的工作原理
subtitle:   kafka的工作原理
date:       2019-03-06
author:     WPF
header-img: img/post-bg-cook.jpg
catalog: true
tags:
- kafka
- 消息队列
- java
---

## 简介
kafka是一个分布式消息队列。具有高性能、持久化、多副本备份、可拓展等功能。生产者往队列里写消息，消费者从队列里取消息进行业务逻辑。一般在架构设计中起到**解耦、削峰、异步处理、自带重试**的作用。
为了做到水平扩展，一个topic实际是由多个partition组成的，遇到瓶颈时，可以通过增加partition的数量来进行横向扩容。单个parition内是保证消息有序。
每新写一条消息，kafka就是在对应的文件append写，所以性能非常高。

## kafka的数据流

![](https://ws4.sinaimg.cn/large/006tKfTcly1g0ti3le8nmj30ym0u0q6v.jpg)

总结：Producers往Brokers里面的指定Topic中写消息，Consumers从Brokers里面拉去指定Topic的消息，然后进行业务处理。
图中有两个topic，topic 0有两个partition，topic 1有一个partition，三副本备份。可以看到consumer gourp 1中的consumer 2没有分到partition处理。

## kafka的生产流程

![](https://ws2.sinaimg.cn/large/006tKfTcly1g0ti79ob8lj31cp0u0q5s.jpg)

大概的步骤如下：
1. 创建记录。记录中包含topic、value、key、partition。其中key、partition是可选。
2. 序列化
3. 按照topic和partition，放进对应的发送队列中。
4. **批量**发送到kafka brokers中

由于生产的时候partition和key是可选参数，所以：
1. key不为空，按照key进行哈希，相同key去一个partition。
2. key为空，根据round-robin来选partition

#### partition的分配（寻址）和leader选举
kafka中partition的分配是由controller（control其实就是某一个broker，由zk选出）来执行的。执行过程如下：
1. 首先是排序。controller会对kafka的Broker和待分配partition排序。
2. 将第i个Partition分配到第（i % n）个Broker上 （leader的选举）
3. 将第i个partition的第j的副本分配到第（(i+j)%n）的broker上。

上面的算法保证了会尽量多的把多个副本分配到不同的broker上面。

#### Replica的同步策略
follower从leader批量拉取数据的策略是由request.required.acks参数来设置数据的可靠性。

参数|说明
----|----
0|which means that the producer never waits for an acknowledgement from the broker.发过去就完事了，不关心broker是否处理成功，可能丢数据。
1|which means that the producer gets an acknowledgement after the leader replica has received the data. 当写Leader成功后就返回,其他的replica都是通过fetcher去同步的,所以kafka是异步写，主备切换可能丢数据。
-1|which means that the producer gets an acknowledgement after all in-sync replicas have received the data. 要等到isr里所有机器同步成功，才能返回成功，延时取决于最慢的机器。强一致，不会丢数据。

**这个参数的配置主要还是体现一个CAP的问题。一致性和可用性不可兼得。**

## kafka的消费
kafka是以消费组的方式来就行消费的。一个partition只能被同一个消费组里面的一个消费组消费。
#### offset的存储
默认的情况是写入一个叫__consumers_offsets的topic中，这个topic的key是由groupid、topic、partition组成，value是偏移量offset。所有的消费offset都提交写入到上述的Topic中。因为这部分消息是非常重要，以至于是不能容忍丢数据的，所以消息的 acking 级别设置为了 -1，生产者等到所有的 ISR 都收到消息后才会得到 ack（数据安全性极好，当然，其速度会有所影响）。所以 Kafka 又在内存中维护了一个关于 GroupID，Topic 和 Partition 的三元组来维护最新的 offset 信息，消费者获取最新的offset的时候会直接从内存中获取。



